import re
import time
import requests
import pickle
import pandas as pd
from pathlib import Path
from typing import Union, List
from ontology.ontology import OntologyType, Strategy, ConversionResult, FailedId , OntologyBaseConverter
from .types import DiseaseOntologyFileFormat

DISEASE_DICT = OntologyType(type="Disease", default="DOID", choices=["DOID", "MESH"])


class Disease(OntologyBaseConverter):
    """Convert the disease id to a standard format for the knowledge graph."""
    def __init__(self, ids, strategy=Strategy.MIXTURE, batch_size: int=300, sleep_time: int=3):
        """Initialize the Disease class for id conversion.

        Args:
            ids (List[str]): A list of disease ids (Currently support DOID and MESH).
            strategy (Strategy, optional): The strategy to keep the results. Defaults to Strategy.MIXTURE, it means that the results will mix different database ids.
            batch_size (int, optional): The batch size for each request. Defaults to 300.
            sleep_time (int, optional): The sleep time between each request. Defaults to 3.
        """
        super().__init__(ontology_type=DISEASE_DICT, ids=ids, strategy=strategy, 
                         batch_size=batch_size, sleep_time=sleep_time)

        # More details on the database_url can be found here: https://www.ebi.ac.uk/spot/oxo/index
        self._database_url = "https://www.ebi.ac.uk/spot/oxo/api/search"
    
    def _format_response(self, response: dict, batch_ids: List[str]) -> None:
        """Format the response from the OXO API.
        
        Args:
            response (dict): The response from the OXO API. It was generated by the resp.json() method.
            batch_ids (List[str]): The list of ids for the current batch.

        Raises:
            Exception: If no results found.

        Returns:
            None
        """
        search_results = response.get("_embedded", {}).get("searchResults", [])
        if len(search_results) == 0:
            raise Exception("No results found")
        
        print("Batch size: %s, results size: %s" % (len(batch_ids), len(search_results)))
        for (index, id) in enumerate(batch_ids):
            prefix, value = id.split(":")
            if prefix not in self.databases:
                failed_id = FailedId(idx=index, id=id, 
                                     reason="Invalid prefix, only support %s" % self.databases)
                self._failed_ids.append(failed_id)
                continue

            result = search_results[index]
            mapping_response_list = result.get("mappingResponseList", [])
            if len(mapping_response_list) == 0:
                failed_id = FailedId(idx=index, id=id, reason="No results found")
                self._failed_ids.append(failed_id)
                continue
            else:
                converted_id_dict = {}
                converted_id_dict[prefix] = id
                converted_id_dict["raw_id"] = id
                difference = [x for x in self.databases if x != prefix]
                for choice in difference:
                    # The prefix maybe case insensitive, such as MeSH:D015161. But we need to keep all the prefix in upper case.
                    matched = list(filter(lambda x: re.match(r"^%s.*" % choice, x.get("curie"), re.I.IGNORECASE), mapping_response_list))
                    if len(matched) > 0:
                        converted_ids = [f'{choice}:{x.get("curie").split(":")[1]}' for x in matched]
                        converted_id_dict[choice] = converted_ids
                        converted_id_dict["idx"] = index

                        if choice == self.default_database and len(converted_ids) > 1:
                            failed_id = FailedId(idx=index, id=id, reason="Multiple results found")
                            self._failed_ids.append(failed_id)
                            # Abandon the converted_id_dict, otherwise the converted_ids will be added to the converted_ids list.
                            converted_id_dict = {}
                            break

                        if self._strategy == Strategy.UNIQUE and len(converted_ids) > 1:
                            failed_id = FailedId(idx=index, id=id, reason="The strategy is unique, but multiple results found")
                            self._failed_ids.append(failed_id)
                            # Abandon the converted_id_dict, otherwise the converted_ids will be added to the converted_ids list.
                            converted_id_dict = {}
                            break
                    else:
                        converted_id_dict[choice] = None

                if converted_id_dict:
                    self._converted_ids.append(converted_id_dict)
    
    def _fetch_ids(self, ids) -> dict:
        """Fetch the ids from the OXO API.

        Args:
            ids (List[str]): A list of ids.

        Returns:
            dict: The response from the OXO API which was generated by the resp.json() method.
        """
        headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36"
        }
        results = requests.post(self._database_url, headers=headers, json={
            "ids": ids, 
            "inputSource" : None,
            "mappingTarget" : self.databases,
            "mappingSource" : self.databases,
            "distance" : 1
        }, params={"size": self._batch_size})

        return results.json()
    
    def convert(self) -> ConversionResult:
        """Convert the ids to different databases.

        Returns:
            ConversionResult: The results of id conversion.
        """
        # Cannot use the parallel processing, otherwise the index order will not be correct.
        for i in range(0, len(self._ids), self._batch_size):
            batch_ids = self._ids[i:i+self._batch_size]
            response = self._fetch_ids(batch_ids)
            self._format_response(response, batch_ids)
            time.sleep(self._sleep_time)

        return ConversionResult(
            ids=self._ids,
            strategy=self._strategy,
            converted_ids=self._converted_ids,
            databases=self._databases,
            default_database=self._default_database,
            database_url=self._database_url,
            failed_ids=self._failed_ids
        )
    

class DiseaseOntologyFormatter:
    """Format the disease ontology file."""
    def __init__(self, filepath: Union[str, Path], dict: ConversionResult=None, **kwargs) -> None:
        """Initialize the DiseaseOntologyFormatter class.
        
        Args:
            filepath (Union[str, Path]): The path of the disease ontology file. Only support csv and tsv file.
            dict (ConversionResult, optional): The results of id conversion. Defaults to None.
            **kwargs: The keyword arguments for the Disease class.
        """
        self._filepath = filepath
        self._data = self._read_file()
        self._formatted_data = None
        self._failed_formatted_data = None
        self._expected_columns = [e.value for e in DiseaseOntologyFileFormat]

        self._check_format()

        if dict is None:
            self._dict = Disease(ids=self._data[DiseaseOntologyFileFormat.ID.value].tolist(), **kwargs).convert()
        else:
            self._dict = dict

    @property
    def data(self) -> pd.DataFrame:
        return self._data
    
    @property
    def formatted_data(self) -> pd.DataFrame:
        return self._formatted_data
    
    @property
    def failed_formatted_data(self) -> pd.DataFrame:
        return self._failed_formatted_data
    
    @property
    def dict(self) -> ConversionResult:
        return self._dict
    
    @property
    def filepath(self) -> Union[str, Path]:
        return self._filepath

    def _read_file(self) -> pd.DataFrame:
        """Read the disease ontology file.
        
        Returns:
            pd.DataFrame: The disease ontology data.
        """
        path = Path(self._filepath)
        ext = path.suffix.strip(".")
        delimiter = "," if ext == "csv" else "\t"
        return pd.read_csv(path, delimiter=delimiter)
    
    def _check_format(self) -> bool:
        """Check the format of the disease ontology file.

        Returns:
            bool: True if the format is correct, otherwise raise an exception.
        """
        columns = self._data.columns.tolist()
        missed_columns = []
        for col in self._expected_columns:
            if col not in columns:
                missed_columns.append(col)
        
        if len(missed_columns) > 0:
            raise Exception("The file format is not correct, missed columns: %s" % ", ".join(missed_columns))
        return True
    
    def format(self):
        """Format the disease ontology file.
        
        Returns:
            self: The DiseaseOntologyFormatter instance.
        """
        formated_data = []
        failed_formatted_data = []

        for converted_id in self._dict.converted_ids:
            raw_id = converted_id.get("raw_id")
            row = self._data[self._data[DiseaseOntologyFileFormat.ID.value] == raw_id]
            id = converted_id.get(DISEASE_DICT.default)
            new_row = {key: row[key].values[0] for key in self._expected_columns}

            if type(id) == list and len(id) > 1:
                new_row["aliases"] = "|".join(id)
                row["reason"] = "Multiple results found"
                failed_formatted_data.append(new_row)                
            else:
                if type(id) == list and len(id) == 1:
                    id = id[0]

                new_row[DiseaseOntologyFileFormat.ID.value] = id
                new_row[DiseaseOntologyFileFormat.RESOURCE.value] = DISEASE_DICT.default
                new_row[DiseaseOntologyFileFormat.LABEL.value] = DISEASE_DICT.type

                ids = [converted_id.get(x) for x in DISEASE_DICT.choices if x != DISEASE_DICT.default]
                unique_ids = []
                for id in ids:
                    if type(id) == list:
                        unique_ids.extend(id)
                    elif type(id) == str and id not in unique_ids:
                        unique_ids.append(id)

                new_row["aliases"] = "|".join(unique_ids)

                formated_data.append(new_row)

        for failed_id in self._dict.failed_ids:
            id = failed_id.id
            prefix, value = id.split(":")
            row = self._data[self._data[DiseaseOntologyFileFormat.ID.value] == id]
            new_row = {key: row[key].values[0] for key in self._expected_columns}
            new_row[DiseaseOntologyFileFormat.ID.value] = id
            new_row[DiseaseOntologyFileFormat.LABEL.value] = DISEASE_DICT.type
            new_row[DiseaseOntologyFileFormat.RESOURCE.value] = prefix
            new_row["aliases"] = ""

            # Keep the original record if the id match the default prefix.
            if prefix == DISEASE_DICT.default or self._dict.strategy == Strategy.MIXTURE:
                formated_data.append(new_row)
            else:
                new_row["reason"] = failed_id.reason
                failed_formatted_data.append(new_row)
        
        if len(formated_data) > 0:
            self._formatted_data = pd.DataFrame(formated_data)

        if len(failed_formatted_data) > 0:
            self._failed_formatted_data = pd.DataFrame(failed_formatted_data)

        return self
    
    def filter(self) -> pd.DataFrame:
        pass

    def write(self, filepath: Union[str, Path]):
        """Write the formatted data to the file.

        Args:
            filepath (Union[str, Path]): The file path to write the formatted data. The file extension should be .tsv. Three files will be generated: the formatted data, the failed formatted data and the pickle file.
        """
        if self._formatted_data is None:
            raise Exception("Cannot find the valid formatted data, maybe the format method is not called or the formatted data is empty (please check the failed_formatted_data attributes).")
        
        if self._formatted_data is not None:
            self._formatted_data.to_csv(filepath, sep="\t", index=False)

        if self._failed_formatted_data is not None:
            self._failed_formatted_data.to_csv(Path(filepath).with_suffix(".failed.tsv"), sep="\t", index=False)

        obj = {
            "dict": self._dict,
            "formatted_data": self._formatted_data,
            "failed_formatted_data": self._failed_formatted_data,
            "filepath": self._filepath,
            "data": self._data
        }

        # Pickle the object
        with open(Path(filepath).with_suffix(".pkl"), "wb") as f:
            pickle.dump(obj, f)


if __name__ == "__main__":
    ids = ["DOID:7402", "DOID:7400", "DOID:7401", "DOID:8731", "DOID:8729", "DOID:8725"]
    disease = Disease(ids=ids)
    result = disease.convert()
